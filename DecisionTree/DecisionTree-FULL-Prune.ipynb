{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd\n",
    "import bootstrapping as bs\n",
    "from TreePlotter import createPlot\n",
    "import stratified_sampling as s_s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ent(data):\n",
    "    labels = Counter(data[:, -1])\n",
    "    values = np.array(list(labels.values()))\n",
    "    values_prob = values / values.sum()\n",
    "    ent = -(values_prob * np.log2(values_prob)).sum()\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_IV(data, axis):\n",
    "    labels = Counter(data[:, axis])\n",
    "    values = np.array(list(labels.values()))\n",
    "    values_prob = values / values.sum()\n",
    "    ent = -(values_prob * np.log2(values_prob)).sum()\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Gini(data):\n",
    "    n = data.shape[0]\n",
    "    data_labels = set(data[:, -1])\n",
    "    labels_info = np.array(list(Counter(data[:, -1]).values()))\n",
    "    gini = 1 - ((labels_info / n) ** 2).sum()\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3_split(data):\n",
    "    feat_size = data.shape[1] - 1\n",
    "    base_ent = calc_ent(data)  \n",
    "    best_info_gain = 0.0 \n",
    "    best_feat = -1 \n",
    "    for i in range(feat_size):\n",
    "        values_on_feat = set(data[:, i])  \n",
    "        new_ent = 0.0  \n",
    "        for value in values_on_feat:\n",
    "            sub_data_set = split_by_value(data, i, value)\n",
    "            prob = sub_data_set.shape[0] * 1.0 / data.shape[0] \n",
    "            new_ent += prob * calc_ent(sub_data_set)  \n",
    "        info_gain = base_ent - new_ent \n",
    "        if (info_gain > best_info_gain):\n",
    "            best_info_gain = info_gain  \n",
    "            best_feat = i  \n",
    "    return best_feat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def C45_split(data):\n",
    "    feat_size = data.shape[1] - 1\n",
    "    base_ent = calc_ent(data)  \n",
    "    best_info_gain_rate = 0.0 \n",
    "    best_feat = -1 \n",
    "    for i in range(feat_size):\n",
    "        values_on_feat = set(data[:, i])  \n",
    "        new_ent = 0.0  \n",
    "        for value in values_on_feat:\n",
    "            sub_data_set = split_by_value(data, i, value)\n",
    "            prob = sub_data_set.shape[0] * 1.0 / data.shape[0] \n",
    "            new_ent += prob * calc_ent(sub_data_set)  \n",
    "        info_gain_rate = (base_ent - new_ent) / calc_IV(data, i)\n",
    "        if (info_gain_rate > best_info_gain_rate):\n",
    "            best_info_gain_rate = info_gain_rate  \n",
    "            best_feat = i  \n",
    "    return best_feat "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CART_split(data):\n",
    "    feat_size = data.shape[1] - 1\n",
    "    base_gini = calc_Gini(data)  \n",
    "    best_gini_gain = 0.0 \n",
    "    best_feat = -1 \n",
    "    for i in range(feat_size):\n",
    "        values_on_feat = set(data[:, i])  \n",
    "        new_gini = 0.0  \n",
    "        for value in values_on_feat:\n",
    "            sub_data_set = split_by_value(data, i, value)\n",
    "            prob = sub_data_set.shape[0] * 1.0 / data.shape[0] \n",
    "            new_gini += prob * calc_Gini(sub_data_set)  \n",
    "        gini_gain = base_gini - new_gini \n",
    "        if (gini_gain > best_gini_gain):\n",
    "            best_gini_gain = gini_gain  \n",
    "            best_feat = i  \n",
    "    return best_feat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_value(data, axis, value):\n",
    "    data_f = data[data[:, axis]==value]\n",
    "    data_r = np.delete(data_f, axis, 1)\n",
    "    return data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(category_list):\n",
    "    return Counter(category_list).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split(data, method):\n",
    "    switcher = {\n",
    "        \"ID3\" : ID3_split,\n",
    "        \"C45\" : C45_split,\n",
    "        \"CART\" : CART_split\n",
    "    }\n",
    "    if method in switcher:\n",
    "        return switcher[method](data)\n",
    "    else:\n",
    "        raise ValueError(\"No such split method called [ %s ]\" % method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_build(data, features_ori, method):\n",
    "    features = features_ori[:]\n",
    "    category_list = data[:, -1]\n",
    "    if Counter(category_list)[category_list[0]] == category_list.shape[0]: \n",
    "        return category_list[0]  \n",
    "    if data.shape[0] == 1: \n",
    "        return majority_vote(category_list) \n",
    "    best_feature = split(data, method)\n",
    "    best_feature_name = features[best_feature]\n",
    "    tree_grow = {best_feature_name: {}} \n",
    "    del (features[best_feature])  \n",
    "    values_on_feat = set(data[:, best_feature])\n",
    "    for value in values_on_feat: \n",
    "        sub_features = features[:]\n",
    "        tree_grow[best_feature_name][value] = tree_build(\n",
    "            split_by_value(data, best_feature, value), sub_features, method)\n",
    "    return tree_grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data, ratio=0.3):\n",
    "    train, test = s_s.stratified(data, ratio=ratio)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(trained_tree, feature_names, test_sample):\n",
    "    feature_key = list(trained_tree.keys())[0]\n",
    "    if feature_key in trained_tree.keys():\n",
    "        feature_value = trained_tree[feature_key]\n",
    "        \n",
    "        classify_res = 'acc'\n",
    "        if feature_key in feature_names:\n",
    "            feature_index = feature_names.index(feature_key)\n",
    "            for key in feature_value.keys():\n",
    "                if test_sample[feature_index] == key:\n",
    "                    if isinstance(feature_value[key], dict):\n",
    "                        classify_res = classify(feature_value[key], feature_names, test_sample)\n",
    "                    else:\n",
    "                        classify_res = feature_value[key]\n",
    "    return classify_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ori_count(tree, validation, features): # error count of origin tree\n",
    "    error = 0.0\n",
    "    for i in range(len(validation)):\n",
    "        res_i = classify(tree, features, validation[i])\n",
    "        if res_i != validation[i][-1]:\n",
    "            error += 1\n",
    "    return float(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pruning_count(major, validation): # error count of pruning tree\n",
    "    error = 0.0\n",
    "    for i in range(len(validation)):\n",
    "        if major != validation[i][-1]:\n",
    "            error += 1\n",
    "    return float(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def post_prune(tree, train, validation, features_ori):\n",
    "    features = features_ori[:]\n",
    "    feature_key = list(tree.keys())[0]\n",
    "    feature_value = tree[feature_key]\n",
    "    category_list = train[:, -1]\n",
    "    feature_index = features.index(feature_key)\n",
    "    del(features[feature_index])\n",
    "    for key in feature_value.keys():\n",
    "        if isinstance(feature_value[key], dict):\n",
    "            sub_feat = features[:]\n",
    "            tree[feature_key][key] = post_prune(\n",
    "                feature_value[key],\n",
    "                split_by_value(train, feature_index, key),\n",
    "                split_by_value(validation, feature_index, key),\n",
    "                sub_feat\n",
    "            )\n",
    "    \n",
    "    ori_err = ori_count(tree, validation, features)\n",
    "    new_err = pruning_count(majority_vote(category_list), validation)\n",
    "    # print(new_err, ori_err)\n",
    "    if ori_err * 0.1 < new_err:\n",
    "        # print(\"Save!\")\n",
    "        return tree\n",
    "    \n",
    "    # print(\"Cut!!\")\n",
    "    return majority_vote(category_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(path):\n",
    "    data_ori = pd.read_csv(path)\n",
    "    data_ori = pd.read_csv(path)\n",
    "    train_ori, test = data_split(data_ori, ratio=0.5)\n",
    "    train = train_ori\n",
    "    validation = test\n",
    "    \n",
    "    features = list(test.columns)\n",
    "    tested_count = test.shape[0]\n",
    "    best_err = 1.0\n",
    "    best_tree = None\n",
    "    best_method = None\n",
    "    for method in ['ID3', 'C45', 'CART']:\n",
    "        trained_tree = tree_build(np.array(train), list(train.columns), method)\n",
    "        error_counts = 0\n",
    "        for i in range(tested_count):\n",
    "            i_info = list(test.iloc[i])\n",
    "            i_data = i_info[:-1]\n",
    "            i_label = i_info[-1]\n",
    "            if not classify(trained_tree, features, i_data)==i_label :\n",
    "                error_counts += 1\n",
    "    \n",
    "        err_rate = 1.0 * error_counts / test.shape[0]\n",
    "        print(\"==================================\")\n",
    "        print(\"--->Based on %s split method\" % method)\n",
    "        print(\"%d samples tested\\n   error rate is %f\\naccuracy rate is %f\" \n",
    "              % (tested_count, err_rate, 1.0 - err_rate))\n",
    "        if err_rate < best_err:\n",
    "            best_err = err_rate\n",
    "            best_tree = trained_tree\n",
    "            best_method = method\n",
    "    print(\"##################################\")\n",
    "    print(\"the best method for tree-building is [%s]\" % best_method, \n",
    "          \"\\nthe best accuracy is %f\" % (1 - best_err))\n",
    "    \n",
    "    post_tree = post_prune(best_tree, np.array(train), np.array(validation), features)\n",
    "    error_counts = 0\n",
    "    for i in range(tested_count):\n",
    "        i_info = list(test.iloc[i])\n",
    "        i_data = i_info[:-1]\n",
    "        i_label = i_info[-1]\n",
    "        if not classify(post_tree, features, i_data)==i_label :\n",
    "            error_counts += 1\n",
    "    \n",
    "    err_rate = 1.0 * error_counts / test.shape[0]\n",
    "    print(\"==================================\")\n",
    "    print(\"--->Then, make post-pruning \")\n",
    "    print(\"%d samples tested\\n   error rate is %f\\naccuracy rate is %f\" \n",
    "              % (tested_count, err_rate, 1.0 - err_rate))\n",
    "    print(\"\\ndict-based tree model has been returned \")\n",
    "    return post_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\n",
      "--->Based on ID3 split method\n",
      "863 samples tested\n",
      "   error rate is 0.076477\n",
      "accuracy rate is 0.923523\n",
      "==================================\n",
      "--->Based on C45 split method\n",
      "863 samples tested\n",
      "   error rate is 0.077636\n",
      "accuracy rate is 0.922364\n",
      "==================================\n",
      "--->Based on CART split method\n",
      "863 samples tested\n",
      "   error rate is 0.095017\n",
      "accuracy rate is 0.904983\n",
      "##################################\n",
      "the best method for tree-building is [ID3] \n",
      "the best accuracy is 0.923523\n",
      "==================================\n",
      "--->Then, make post-pruning \n",
      "863 samples tested\n",
      "   error rate is 0.067207\n",
      "accuracy rate is 0.932793\n",
      "\n",
      "dict-based tree model has been returned \n"
     ]
    }
   ],
   "source": [
    "car_tree = decision_tree(\"car.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
