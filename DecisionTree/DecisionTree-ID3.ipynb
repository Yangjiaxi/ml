{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_ent(data):\n",
    "    labels = Counter(data[:,-1])\n",
    "    values = np.array(list(labels.values()))\n",
    "    values_prob = values / values.sum()\n",
    "    ent = -(values_prob * np.log2(values_prob)).sum()\n",
    "    return ent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_by_value(data, axis, value):\n",
    "    data_f = data[data[:, axis]==value]\n",
    "    data_r = np.delete(data_f, axis, 1)\n",
    "    return data_r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ID3_split(data):\n",
    "    feat_size = data.shape[1] - 1\n",
    "    base_ent = calc_ent(data)  \n",
    "    best_info_gain = 0.0 \n",
    "    best_feat = -1 \n",
    "    for i in range(feat_size):\n",
    "        values_on_feat = set(data[:, i])  \n",
    "        new_ent = 0.0  \n",
    "        for value in values_on_feat:\n",
    "            sub_data_set = split_by_value(data, i, value)\n",
    "            prob = sub_data_set.shape[0] * 1.0 / data.shape[0] \n",
    "            new_ent += prob * calc_ent(sub_data_set)  \n",
    "        info_gain = base_ent - new_ent \n",
    "        if (info_gain > best_info_gain):\n",
    "            best_info_gain = info_gain  \n",
    "            best_feat = i  \n",
    "    return best_feat  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def majority_vote(category_list):\n",
    "    return Counter(category_list).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tree_build(data, features_ori):\n",
    "    features = features_ori[:]\n",
    "    category_list = data[:, -1]\n",
    "    if Counter(category_list)[category_list[0]] == category_list.shape[0]: \n",
    "        return category_list[0]  \n",
    "    if data.shape[0] == 1: \n",
    "        return majority_vote(category_list) \n",
    "    best_feature = ID3_split(data)  \n",
    "    # print(\"best: \", bestFeat)\n",
    "    best_feature_name = features[best_feature]\n",
    "    tree_grow = {best_feature_name: {}} \n",
    "    del (features[best_feature])  \n",
    "    values_on_feat = set(data[:, best_feature])\n",
    "    for value in values_on_feat: \n",
    "        sub_features = features[:]\n",
    "        tree_grow[best_feature_name][value] = tree_build(\n",
    "            split_by_value(data, best_feature, value), sub_features)\n",
    "    return tree_grow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify(trained_tree, feature_names, test_sample):\n",
    "    feature_key = list(trained_tree.keys())[0]\n",
    "    feature_value = trained_tree[feature_key]\n",
    "    feature_index = feature_names.index(feature_key)\n",
    "    classify_res = 'Unknown'\n",
    "    for key in feature_value.keys():\n",
    "        if test_sample[feature_index] == key:\n",
    "            if isinstance(feature_value[key], dict):\n",
    "                classify_res = classify(feature_value[key], feature_names, test_sample)\n",
    "            else:\n",
    "                classify_res = feature_value[key]\n",
    "    return classify_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_split(data):\n",
    "    import bootstrapping as bs\n",
    "    _label = np.zeros(data.shape[0])\n",
    "    train, _, test, _ = bs.bootstrapping(data, _label)\n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decision_tree(path):\n",
    "    data_ori = pd.read_csv(path)\n",
    "    train, test = data_split(data_ori)\n",
    "    car_tree = tree_build(np.array(train), list(train.columns))\n",
    "    features = list(test.columns)\n",
    "    error_counts = 0\n",
    "    tested_count = test.shape[0]\n",
    "    for i in range(tested_count):\n",
    "        i_info = list(test.iloc[i])\n",
    "        i_data = i_info[:-1]\n",
    "        i_label = i_info[-1]\n",
    "        if not classify(car_tree, features, i_data)==i_label :\n",
    "            error_counts += 1\n",
    "        # print(\"error!, at \", i)\n",
    "\n",
    "    err_rate = 1.0 * error_counts / test.shape[0]\n",
    "    print(\"%d samples tested\\nerror rate is %f\\n  acc rate is %f\" \n",
    "          % (tested_count, err_rate, 1.0 - err_rate))\n",
    "    return car_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "395 samples tested\n",
      "error rate is 0.108861\n",
      "  acc rate is 0.891139\n"
     ]
    }
   ],
   "source": [
    "car_tree = decision_tree(\"car.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
