{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "from collections import Counter\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_stop_words(file):\n",
    "    swl = []\n",
    "    with open(file, encoding='utf-8') as sw:\n",
    "        swl.extend(sw.read().split('\\n'))\n",
    "    return np.array(swl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_folder(path, stop_words):\n",
    "    for files in (os.path.join(path, files_name) for files_name in os.listdir(path)):\n",
    "        with open(files, encoding='utf-8') as txt:\n",
    "            uni = np.array(list(set(re.findall(r'\\w+', re.sub('<br />', ' ', txt.read().lower())))))\n",
    "            yield np.setdiff1d(uni, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_word_frequency(path, stop_words):\n",
    "    files_count = len(os.listdir(path))\n",
    "    i = 1\n",
    "    total = Counter()\n",
    "    for t in read_folder(path, stop_words):\n",
    "        each = Counter(t)\n",
    "        total.update(each)\n",
    "        if i % (0.2 * files_count) == 0:\n",
    "            print(\" %d/%d \" % (i, files_count), end='..')\n",
    "        i += 1\n",
    "    print(\"\\nSuccess!\")\n",
    "    res = np.array(total.most_common())\n",
    "    res[:, 1] = res[:, 1].astype('int32') / files_count\n",
    "    res[:, 1] = np.log(res[:, 1].astype('float64'))  # 取对数，PI(a,b,c,d) = SIGMA(a,b,c,d) 过小的数字乘起来会趋0\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def prefix(path, stop_words):\n",
    "    with open(path, encoding='utf-8') as txt:\n",
    "        uni = np.array(list(set(re.findall(r'\\w+', re.sub('<br />', ' ', txt.read().lower())))))\n",
    "        return np.setdiff1d(uni, stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_test(path, goal, stop_words, train_pos_dict, train_neg_dict):\n",
    "    files_count = len(os.listdir(path))\n",
    "    i = 1\n",
    "    err_count = 0\n",
    "    for files in (os.path.join(path, files_name) for files_name in os.listdir(path)):\n",
    "        if i % (0.1 * files_count) == 0:\n",
    "            print(\"%5d samples tested, acc is %f\" % (i, (1 - float(err_count) / files_count) * 100))\n",
    "        fixed = prefix(files, stop_words)\n",
    "        pos_score = 0.0\n",
    "        neg_score = 0.0\n",
    "        for word in fixed:\n",
    "            if word in train_pos_dict:\n",
    "                pos_score += float(train_pos_dict[word])\n",
    "            if word in train_neg_dict:\n",
    "                neg_score += float(train_neg_dict[word])\n",
    "        i += 1\n",
    "        if (pos_score - neg_score) * goal >= 0:\n",
    "            continue\n",
    "        else:\n",
    "            err_count += 1\n",
    "    return (1 - float(err_count) / files_count) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def model(train_pos_path, train_neg_path, test_pos_path, test_neg_path, stop_words_path):\n",
    "    d = {'train_pos_path': train_pos_path,\n",
    "         'train_neg_path': train_neg_path,\n",
    "         'test_pos_path': test_pos_path,\n",
    "         'test_neg_path': test_neg_path,\n",
    "         's_w_path': stop_words_path}\n",
    "    stop_words = load_stop_words(stop_words_path)\n",
    "    print(\"*******Loading Positive Data*************************\")\n",
    "    train_pos_data = get_word_frequency(train_pos_path, stop_words)\n",
    "    print(\"*******Loading Negative Data*************************\")\n",
    "    train_neg_data = get_word_frequency(train_neg_path, stop_words)\n",
    "    train_pos_dict = dict(train_pos_data)\n",
    "    train_neg_dict = dict(train_neg_data)\n",
    "    print(\"*******Positive Tests:*******************************\")\n",
    "    d['test_pos_acc'] = load_test(test_pos_path, 1, stop_words, train_pos_dict, train_neg_dict)\n",
    "    print(\"*******Negative Tests:*******************************\")\n",
    "    d['test_neg_acc'] = load_test(test_neg_path, -1, stop_words, train_pos_dict, train_neg_dict)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*******Loading Positive Data*************************\n",
      " 2500/12500 .. 5000/12500 .. 7500/12500 .. 10000/12500 .. 12500/12500 ..\n",
      "Success!\n",
      "*******Loading Negative Data*************************\n",
      " 2500/12500 .. 5000/12500 .. 7500/12500 .. 10000/12500 .. 12500/12500 ..\n",
      "Success!\n",
      "*******Positive Tests:*******************************\n",
      " 1000 samples tested, acc is 97.710000\n",
      " 2000 samples tested, acc is 95.560000\n",
      " 3000 samples tested, acc is 93.500000\n",
      " 4000 samples tested, acc is 91.050000\n",
      " 5000 samples tested, acc is 88.720000\n",
      " 6000 samples tested, acc is 86.050000\n",
      " 7000 samples tested, acc is 83.470000\n",
      " 8000 samples tested, acc is 81.210000\n",
      " 9000 samples tested, acc is 78.660000\n",
      "10000 samples tested, acc is 76.030000\n",
      "*******Negative Tests:*******************************\n",
      " 1000 samples tested, acc is 96.680000\n",
      " 2000 samples tested, acc is 93.730000\n",
      " 3000 samples tested, acc is 90.710000\n",
      " 4000 samples tested, acc is 87.660000\n",
      " 5000 samples tested, acc is 84.730000\n",
      " 6000 samples tested, acc is 81.770000\n",
      " 7000 samples tested, acc is 78.660000\n",
      " 8000 samples tested, acc is 75.580000\n",
      " 9000 samples tested, acc is 72.210000\n",
      "10000 samples tested, acc is 68.990000\n"
     ]
    }
   ],
   "source": [
    "result = model('aclImdb/train/pos/',\n",
    "               'aclImdb/train/neg/',\n",
    "               'aclImdb/test/pos/',\n",
    "               'aclImdb/test/neg/',\n",
    "               'stop_words.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_pos_path \t: aclImdb/train/pos/\n",
      "train_neg_path \t: aclImdb/train/neg/\n",
      "test_pos_path \t: aclImdb/test/pos/\n",
      "test_neg_path \t: aclImdb/test/neg/\n",
      "s_w_path \t: stop_words.txt\n",
      "test_pos_acc \t: 76.03\n",
      "test_neg_acc \t: 68.99\n"
     ]
    }
   ],
   "source": [
    "for k in result:\n",
    "    print(str(k) + \" \\t: \" + str(result[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
