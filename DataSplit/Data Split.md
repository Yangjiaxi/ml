# 数据分割

1. 留出法 `hold-out`

   - 直接划分$D$，$D=S\cup T,S\cap T=\emptyset$
   - 划分尽可能保持数据分布的一致性
   - 留出法应当多次使用，$N$次实验后的平均作为评价结果
   - 缺点：当数据集较小时无法准确反映学习器的性能
   - [一般而言，测试集至少应含30个样例]

2. 交叉验证法 `cross validation`

   - 划分为$k$个大小相似的**互斥**子集 

     $D=D_{1}\cup D_{2}\cup ... \cup D_{k},\quad D_{i}\cap D_{j}=\emptyset(i\not=j)$

   - 常用$k$为10 => [10折交叉验证]

   - - 使用除$D_{k}$外的$k-1$个子集进行训练
     - 使用$D_{k}$检验

   - - 划分方法可能造成误差，所以要使用$p$种划分方法 -> $p$次$k$折验证
     - 总检验次数：$p*k$

   - `EXTRA`:留一法 `Leave-One-Out[LOO]`

     - $|D|=m, k=m$，得到$m$个单元素子集
     - 优于训练集与样本原集仅相差一个元素，所以留一法的评估结果往往被认为比较准确
     - 当$m$较大时，时间开销难以忍受[主要缺点]

3. 自助法 `bootstrapping`

   - 给定包含$m$个样本的数据集$D$
   - 对D采样产生数据集$D'$
     - 从$D$中随机挑选一个元素，拷贝后放入$D'$
     - 重复动作$m$次
   - $m$次操作后，必有元素多次出现，必有元素始终未出现
   - 得到数据集$D'$，就是自助采样的结果
   - 分析：
     - $m$个元素，每个元素每次被选到的概率是$\frac{1}{m}$，故不被选到的概率是$1-\frac{1}{m}$
     - 故$m$次抽取始终不被选到的概率是$(1-\frac{1}{m})^{m}$
     - 取极限${\lim_{m \to \infty}(1-\frac{1}{m})^{m}} \to \frac{1}{e} \approx 0.368 \approx \frac{1}{3}$
     - 我们有数据总量约$1/3$的、没在训练集中出现的样本能用于测试[包外估计]
   - 在数据集较小、难以划分时，自助法很有用