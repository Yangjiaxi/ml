{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# This is a CUDA **Only** program."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torchvision.models as models\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imageio\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image,ImageFont,ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import copy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "content_layers = ['conv_4']\n",
    "style_layers = ['conv_1', 'conv_2', 'conv_3', 'conv_4', 'conv_5']\n",
    "cnn = (models.vgg19(pretrained=True).features).cuda().eval()\n",
    "unloader = transforms.ToPILImage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(image_path, transform=None, max_size=None, shape=None):\n",
    "    image = Image.open(image_path)\n",
    "    \n",
    "    if max_size:\n",
    "        scale = max_size / max(image.size)\n",
    "        size = np.array(image.size) * scale\n",
    "        image = image.resize(size.astype(int), Image.ANTIALIAS)\n",
    "    \n",
    "    if shape:\n",
    "        image = image.resize(shape, Image.LANCZOS)\n",
    "    \n",
    "    if transform:\n",
    "        image = transform(image).unsqueeze(0)\n",
    "    \n",
    "    return image.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show(tensor):\n",
    "    image = tensor.cpu().clone()\n",
    "    image = image.squeeze(0)      # remove the fake batch dimension\n",
    "    image = unloader(image)\n",
    "    plt.imshow(image)\n",
    "    plt.pause(0.1)  # pause a bit so that plots are updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_gram(featmap):\n",
    "    bSize, map_num, m, n = featmap.size()\n",
    "    feat = featmap.view(bSize * map_num, m * n)\n",
    "    G = torch.mm(feat, feat.t())\n",
    "    return G.div(bSize * map_num * m * n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class content_loss(nn.Module):\n",
    "    def __init__(self, content, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.func = nn.MSELoss()\n",
    "        self.content = content.detach() * weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.loss = self.func(input * self.weight, self.content)\n",
    "        return input\n",
    "\n",
    "    def backward(self):\n",
    "        self.loss.backward(retain_graph=True)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class style_loss(nn.Module):\n",
    "    def __init__(self, target, weight):\n",
    "        super().__init__()\n",
    "        self.weight = weight\n",
    "        self.func = nn.MSELoss()\n",
    "        self.target = cal_gram(target).detach() * weight\n",
    "\n",
    "    def forward(self, input):\n",
    "        self.output = input.clone()\n",
    "        self.G = cal_gram(input)\n",
    "        self.G.mul_(self.weight)\n",
    "        self.loss = self.func(self.G, self.target)\n",
    "        return self.output\n",
    "\n",
    "    def backward(self):\n",
    "        self.loss.backward(retain_graph=True)\n",
    "        return self.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cal_loss(cnn, origin, target):\n",
    "    cnn = copy.deepcopy(cnn)\n",
    "    model = nn.Sequential().cuda()\n",
    "    C_losses = []\n",
    "    S_losses = []\n",
    "    i = 0\n",
    "    for L in cnn.children():\n",
    "        if isinstance(L, nn.Conv2d):\n",
    "            i += 1\n",
    "            name = 'conv_{}'.format(i)\n",
    "        elif isinstance(L, nn.ReLU):\n",
    "            name = 'relu_{}'.format(i)\n",
    "            L = nn.ReLU(inplace=False)\n",
    "        elif isinstance(L, nn.MaxPool2d):\n",
    "            name = 'pool_{}'.format(i)\n",
    "            model.add_module(name, L)\n",
    "            continue\n",
    "        model.add_module(name, L)\n",
    "\n",
    "        if name in content_layers:\n",
    "            contentFeat = model(origin).detach()\n",
    "            C_loss = content_loss(contentFeat, content_weight)\n",
    "            model.add_module(\"content_loss{}\".format(i), C_loss)\n",
    "            C_losses.append(C_loss)\n",
    "\n",
    "        if name in style_layers:\n",
    "            styleFeat = model(target).detach()\n",
    "            S_loss = style_loss(styleFeat, style_weight)\n",
    "            model.add_module(\"style_loss{}\".format(i), S_loss)\n",
    "            S_losses.append(S_loss)\n",
    "    return model, C_losses, S_losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_gif(up):\n",
    "    filelist = []  \n",
    "    root = os.getcwd()\n",
    "    pathr = os.path.join(root, up)\n",
    "    files = os.listdir(pathr)\n",
    "    for f in files:  \n",
    "        if(os.path.isfile(pathr + '/' + f)):\n",
    "            if (os.path.splitext(f)[1] == \".png\"):\n",
    "                filelist.append(f)\n",
    "    ff = sorted(filelist)\n",
    "    images = []\n",
    "    for f in ff:\n",
    "        images.append(imageio.imread(os.path.join(pathr, f)))\n",
    "    imageio.mimsave(os.path.join(pathr, 'res.gif'), images, duration=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(cnn, s_origin, s_target):\n",
    "    part1 = os.path.splitext(os.path.split(s_origin)[-1])[0]\n",
    "    part2 = os.path.splitext(os.path.split(s_target)[-1])[0]\n",
    "    up = part1 + '-' + part2 + '-' + \"{}-{}\".format(int(content_weight), int(style_weight))\n",
    "    \n",
    "    if not os.path.exists(up):\n",
    "        os.mkdir(up)\n",
    "    transform = transforms.Compose([transforms.ToTensor()])\n",
    "    origin = load_image(s_origin, transform, max_size=max_size)\n",
    "    target = load_image(s_target, transform, shape=[origin.shape[3], origin.shape[2]])\n",
    "    \n",
    "    if part1 == 'null':\n",
    "        input_img = torch.randn_like(target)\n",
    "        origin = input_img\n",
    "    else:\n",
    "        input_img = origin.clone()\n",
    "    \n",
    "    run = [0]\n",
    "    torchvision.utils.save_image(input_img, \"{}/{:03d}.png\".format(up, run[0]))\n",
    "\n",
    "    model, C_losses, S_losses = cal_loss(cnn, origin, target)\n",
    "    prama = nn.Parameter(input_img.data)\n",
    "    optimizer = optim.LBFGS([prama])\n",
    "    while run[0] <= num_steps:\n",
    "        def closure():\n",
    "            prama.data.clamp_(0, 1)\n",
    "            optimizer.zero_grad()\n",
    "            model(prama)\n",
    "            style_score = 0\n",
    "            content_score = 0\n",
    "            for sl in S_losses:\n",
    "                style_score += sl.backward()\n",
    "            for cl in C_losses:\n",
    "                content_score += cl.backward()\n",
    "\n",
    "            run[0] += 1\n",
    "            if run[0] % record_each == 0:\n",
    "                name = \"{}/{:03d}.png\".format(up, run[0])\n",
    "                torchvision.utils.save_image(prama.data, name)\n",
    "                im = Image.open(name)\n",
    "                draw = ImageDraw.Draw(im)\n",
    "                newfont = ImageFont.truetype('simkai.ttf', 20)\n",
    "                draw.text((0,0),\"{}/{}\".format(run[0], num_steps),(0,0,0),font=newfont)\n",
    "                im.save(name)\n",
    "                print(\"step {}/{}, Style Loss : {:4f} Content Loss: {:4f}\".format(\n",
    "                    run[0], num_steps, style_score.item(), content_score.item()))\n",
    "            if run[0] % show_each == 0:\n",
    "                show(prama.data)\n",
    "            return style_score + content_score\n",
    "        optimizer.step(closure)\n",
    "    prama.data.clamp_(0, 1)\n",
    "    return prama.data, up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_size = 512\n",
    "num_steps = 200\n",
    "record_each = 10\n",
    "show_each = 50\n",
    "content_weight = 1\n",
    "style_weight = 1e3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_origin = \"source/origin/lion.jpg\"\n",
    "s_target = \"source/star/star_1.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out, up = transfer(cnn, s_origin, s_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "make_gif(up)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
